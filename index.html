<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

    <meta name="keywords"
          content="iccv, workshop, computer vision, computer graphics, visual learning, simulation environments, robotics, machine learning, natural language processing, reinforcement learning">

    <link rel="shortcut icon" href="2022/img/website_logo2022.png">


    <title>Urban3D: The 2nd Challenge on Large Scale Point-cloud Analysis for Urban Scenes Understanding</title>
    <meta name="description"
          content="Urban3D: The 2nd Challenge on Large Scale Point-cloud Analysis for Urban Scenes Understanding ---">

    <!--Open Graph Related Stuff-->
    <meta property="og:title" content="Challenge on Large Scale Point-cloud Analysis for Urban Scenes Understanding"/>
    <meta property="og:url" content="https://urban3dchallenge.github.io/"/>
    <meta property="og:description"
          content="Urban3D: The 2nd Challenge on Large Scale Point-cloud Analysis for Urban Scenes Understanding ---"/>
    <meta property="og:site_name"
          content="Urban3D: The 2nd Challenge on Large Scale Point-cloud Analysis for Urban Scenes Understanding"/>
    <meta property="og:image" content=""/>
    <meta property="og:image:url" content=""/>

    <!--Twitter Card Stuff-->
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:title"
          content="Urban3D: The 1st Challenge on Large Scale Point-cloud Analysis for Urban Scenes Understanding"/>
    <meta name="twitter:image" content="https://github.com/Urban3DChallenge/2022/img/website_logo2022.png">
    <meta name="twitter:url" content="urban3dchallenge.github.io"/>
    <meta name="twitter:description"
          content="Urban3D: The 2nd Challenge on Large Scale Point-cloud Analysis for Urban Scenes Understanding ---"/>

    <!-- CSS  -->
    <link rel="stylesheet" type="text/css" href="./2022/css/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="./2022/css/main.css?2" media="screen,projection">

    <!-- Font Awesome -->
    <script src="/static/js/jquery.min.js?1"></script>
    <script src="https://kit.fontawesome.com/ff6e9b10da.js" crossorigin="anonymous"></script>
    <script src="/static/js/moment.min.js?1"></script>
    <script src="/static/js/main.js?2"></script>
</head>

<body>

<style>
    #year-header {
        border: none;
        display: block;
        width: 100%;
        background: #eaebea;
    }

    #year-header ul {
        display: block;
        margin: 0;
        margin-block-start: 0;
        margin-block-end: 0;
        padding-inline-start: 0;
        text-align: center;
    }

    #year-header ul li {
        display: inline-block;
        list-style: none;
    }

    #year-header ul li a {
        display: block;
        text-decoration: none;
        border: none;

        padding: 0 1.7em;
        height: 3.2em;
        line-height: 3.2em;
        vertical-align: middle;

        font-family: Helvetica, Arial, sans-serif;
        font-size: 1.0em;
        font-weight: 400;
        color: #444;
    }

    @media (max-width: 1000px) {
        #year-header ul li a {
            font-size: 0.8em;
        }
    }

    #year-header ul li a:hover {
        background: #dddedd;
        color: #000;
        transition: .5s;
    }
</style>

<div class="navbar navbar-default sticky-top">
    <div class="container">

        <div class="navbar-header">
            <a class="navbar-brand" href="/"></a>
            <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
        </div>


        <div class="navbar-collapse collapse" id="navbar-main">
            <ul class="nav navbar-nav">
                <li><a href="#intro">Introduction</a></li>
                <li><a href="#calls">Call for Contributions</a></li>
                <li><a href="#dates">Important Dates</a></li>
                <!--<li><a href="#schedule">Schedule</a></li>-->
                <li><a href="#speakers">Invited Speakers</a></li>
                <!-- <li><a href="#awards">Awards</a></li> -->
                <li><a href="#Invited Panel Speakers">Panel</a></li>
                <!--                <li><a href="#accepted">Accepted Papers</a></li>-->
                <li><a href="#organizers">Organizers</a></li>
                <!--<li><a href="#programcommittee">Program Committee</a></li>-->
                <li><a href="#sponsors">Sponsors</a></li>

                <li><a href="#sponsors">Previous</a></li>

            </ul>
        </div>

    </div>
</div>


<div class="container">
    <div class="page-content">
        <p><br/></p>
        <div class="row">
            <div class="col-xs-12">
                <img class="img-fluid" src="2022/img/website_logo2022.png"/>
                <!--                <small style="float:right;margin-top:1mm;margin-right:5mm;">Image credit to <a-->
                <!--                        href="https://pixabay.com/users/danielhannah-8058574" target="_blank">Daniel Hannah</a></small>-->
                <!--<center>Date TBD, half-day</center>-->
            </div>
        </div>
        <p><br/></p>

        <div class="row">
            <div class="col-xs-12"><a class="anchor" id="intro"></a>
                <h2>Introduction</h2>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12">
                <p>
                    The 3D world around us is composed of a rich variety of objects: <i> buildings, bridges, trees,
                    cars,
                    rivers,</i> and so forth, each with distinct appearance, morphology, and function. Giving machines
                    the
                    ability to precisely segment and label these diverse objects is of key importance to allow them to
                    interact competently within our physical world, for applications such as scene-level robot
                    navigation, autonomous driving, and even large-scale urban 3D modeling, which is critical for the
                    future of smart city planning and management.
                </p>
                <p>
                    Over the past years, remarkable advances in techniques for 3D point cloud understanding have greatly
                    boosted performance. Although these approaches achieve impressive results for object recognition
                    and semantic segmentation, almost all of them are limited to extremely small 3D point clouds, and
                    are difficult to be directly extended to large-scale point clouds. 
			<font color="red"><b><a
                        href="http://live.bilibili.com/23697730" target="_blank">[Bilibili Live]</a></b></font>
			<font color="red"><b><a
                        href="https://www.youtube.com/watch?v=egBFjbQH8CE" target="_blank">[YouTube Live]</a></b></font>


                </p>
                <p>
                    <!-- <b>The 2nd Challenge on Large Scale Point-cloud Analysis for Urban Scenes Understanding
                        (Urban3D) </b> at <a
                        href="https://eccv2022.ecva.net/" target="_blank">ECCV 2022</a> aims to establish a new
                    benchmark for 3D semantic segmentation on urban-scale point clouds. In particular, we prime the
                    challenge with a dataset, called <b><a
                        href="http://point-cloud-analysis.cs.ox.ac.uk/" target="_blank">SensatUrban</a></b>, which
                    consists of large-scale subsections of multiple
                    urban areas in the UK. With the high quality of per-point annotations and the diverse distribution
                    of semantic categories, the SensatUrban dataset allows us to explore a number of key research
                    problems and directions for 3D semantic learning in this workshop. We aspire to highlight the
                    challenges faced in 3D semantic segmentation on extremely large and dense point clouds of urban
                    environments, sparking innovation in applications such as smart cities, digital twins, autonomous
                    vehicles, automated asset management of large national infrastructures, and intelligent
                    construction sites. We hope that our dataset, and this workshop could inspire the community to
                    explore the next level of 3D semantic learning. Specifically, We encourage researchers from a wide
                    range of background to participate in our challenge, the topics including but not limited to:
                </p> -->
                    <b>The 2nd Challenge on Large Scale Point-cloud Analysis for Urban Scenes Understanding
                        (Urban3D) </b> at <a
                        href="https://eccv2022.ecva.net/" target="_blank">ECCV 2022</a> aims to establish new
                    benchmarks for 3D semantic and instance segmentation on urban-scale point clouds. In particular, we prime the
                    challenge with both <b><a
                        href="http://point-cloud-analysis.cs.ox.ac.uk/" target="_blank">SensatUrban</a></b> and <b><a
                        href="https://www.stpls3d.com//" target="_blank">STPLS3D</a></b> datasets. SensatUrban consists of large-scale subsections of multiple
                    urban areas in the UK. With the high quality of per-point annotations and the diverse distribution
                    of semantic categories. STPLS3D is composed of both real-world and synthetic environments which cover more than 17 km<sup>2</sup> of the city landscape in the U.S. with up to 18 fine-grained semantic classes and 14 instance classes.  
                    These two datasets are complementary to each other and allow us to explore a number of key research
                    problems and directions for 3D semantic and instance learning in this workshop. We aspire to highlight the
                    challenges faced in 3D segmentation on extremely large and dense point clouds of urban
                    environments, sparking innovation in applications such as smart cities, digital twins, autonomous
                    vehicles, automated asset management of large national infrastructures, and intelligent
                    construction sites. We hope that our datasets, and this workshop could inspire the community to
                    explore the next level of 3D learning. Specifically, We encourage researchers from a wide
                    range of background to participate in our challenge, the topics including but not limited to:
                </p>
                <ul>
                    <li>Semantic segmentation of large-scale 3D point clouds.
                    </li>
                    <li>Instance segmentation of 3D point clouds.
                    </li>
                    <li>Weakly supervised learning in 3D point clouds analysis.</li>
                    <li>Learning from imbalanced 3D point clouds.
                    </li>
                    <li>3D point cloud acquisition & visualization.</li>
                    <li>3D object detection & reconstruction.</li>
                    <li>Semi-/weak-/un-/self- supervised learning methods for 3D point clouds.
                    </li>
                </ul>
                We will be hosting 2 invited speakers and holding 2 parallel challenges (i.e., semantic and instance segmentation), and 1 panel discussion session for the topic of point cloud segmentation. More
                information will be provided as soon as possible.
            </div>
        </div>
        <p><br/></p>

        <div class="row">
            <div class="col-xs-12 panel-group"><a class="anchor" id="calls"></a>
                <h2>Call for Contributions</h2>
                <!--                <br/>-->
                <!--                <div class="panel panel-default">-->
                <!--                    <div class="panel-heading" data-toggle="collapse" data-parent="#call" href="#call-papers"-->
                <!--                         style="cursor:pointer;">-->
                <!--                        <h3 style="margin:0;">Full Workshop Papers</h3>-->
                <!--                    </div>-->
                <!--                    <div id="call-papers" class="panel-collapse collapse" data-parent="#call">-->
                <!--                        <div class="panel-body">-->
                <!--                            <p>-->
                <!--                                <span style="font-weight:500;">Submission:</span> We invite authors to submit-->
                <!--                                unpublished papers (8-page <a-->
                <!--                                    href="http://iccv2021.thecvf.com/node/4#submission-guidelines" target="_blank">ICCV-->
                <!--                                format</a>) to our workshop, to be presented at a poster session upon acceptance. All-->
                <!--                                submissions will go through a double-blind review process. All contributions must be-->
                <!--                                submitted (along with supplementary materials, if any) at-->
                <!--                                <a href="https://cmt3.research.microsoft.com/GAZE2021/Submission/Index" target="_blank"-->
                <!--                                   title="CMT Submission System for GAZE 2021">this CMT link</a>.-->
                <!--                            </p>-->
                <!--                            <p>-->
                <!--                                Accepted papers will be published in the official ICCV Workshops proceedings and the-->
                <!--                                Computer Vision Foundation (CVF) Open Access archive.-->
                <!--                            </p>-->
                <!--                            <p>-->
                <!--                                <span style="font-weight:500;">Note:</span> Authors of previously rejected main-->
                <!--                                conference submissions are also welcome to submit their work to our workshop. When doing-->
                <!--                                so, you must submit the previous reviewers' comments (named as <code>previous_reviews.pdf</code>)-->
                <!--                                and a letter of changes (named as <code>letter_of_changes.pdf</code>) as part of your-->
                <!--                                supplementary materials to clearly demonstrate the changes made to address the comments-->
                <!--                                made by previous reviewers.-->
                <!--                                &lt;!&ndash;Due to potential clashes with the main conference reviewing schedule, we will accept simultaneous submissions to the ICCV main conference and GAZE Workshop. Simultaneous submissions are otherwise disallowed.&ndash;&gt;-->
                <!--                            </p>-->
                <!--                        </div>-->
                <!--                    </div>-->
                <!--                </div>-->
                <!--                <br/>-->
                <!--                &lt;!&ndash;-->
                <!--                <div class="panel panel-default">-->
                <!--                  <div class="panel-heading" data-toggle="collapse" data-parent="#call" href="#call-ea" style="cursor:pointer;">-->
                <!--                    <h3 style="margin:0;">Extended Abstracts</h3>-->
                <!--                  </div>-->
                <!--                  <div id="call-ea" class="panel-collapse collapse in" data-parent="#call">-->
                <!--                    <div class="panel-body">-->
                <!--                      <p>-->
                <!--                        In addition to regular papers, we also invite extended abstracts of ongoing or published work (<i>e.g.</i> related papers on ECCV main track). The extended abstracts will not be published or made available to the public (we will only list titles on our website) but will rather be presented during our poster session. We see this as an opportunity for authors to promote their work to an interested audience to gather valuable feedback.-->
                <!--                      </p>-->
                <!--                  <p>-->
                <!--                    Further details on how this poster session will occur online, is to be decided. In general, we will be following the main ECCV conference guidelines and organization in organizing the presentation of all posters.-->
                <!--                      </p>-->
                <!--                      <p>Extended abstracts are limited to six pages and must be created using the <a href="https://eccv2020.eu/author-instructions/" target="_blank">official ECCV format</a>. The submission must be sent to <a href="mailto:openeyes.workshop@gmail.com">openeyes.workshop@gmail.com</a> by the deadline (July 17th).-->
                <!--                      </p>-->
                <!--                      <p>-->
                <!--                        We will evaluate and notify authors of acceptance as soon as possible (evaluation on a rolling basis until the deadline) after receiving their extended abstract submission.-->
                <!--                      </p>-->
                <!--                    </div>-->
                <!--                  </div>-->
                <!--                </div>-->
                <!--                <br>-->
                <!--                &ndash;&gt;-->
                <div class="panel panel-default">
                    <div class="panel-heading" data-toggle="collapse" data-parent="#call" href="#call-challenge"
                         style="cursor:pointer;">
                        <h3 style="margin:0;">Urban3D Challenges@ECCV'2022</h3>
                    </div>
                    <div id="call-challenge" class="panel-collapse collapse in" data-parent="#call">
                        <div class="panel-body">
                            <p>
                                <b>The Urban3D Challenges are hosted on Codalab, and can be found at:</b>
                            </p>
                            <ul>
                                <b>Track 1:</b> 3D Semantic Segmentation of Urban-scale Point Clouds.
                                <ul>
                                    <li><font color="red"><b>Urban3D Challenge</b></font>: <a href="https://competitions.codalab.org/competitions/31519">https://competitions.codalab.org/competitions/31519</a>
                                    </li>
                                    <li>SensatUrban dataset: <a href="http://point-cloud-analysis.cs.ox.ac.uk/">http://point-cloud-analysis.cs.ox.ac.uk/</a>
                                    </li>
                                    <li>SensatUrban API: <a href="https://github.com/QingyongHu/SensatUrban">https://github.com/QingyongHu/SensatUrban</a>
                                    </li>
                                </ul>
                            </ul>
                            <ul>
                                <b>Track 2:</b> 3D Instance Segmentation of Urban-scale Point Clouds.
                                <ul>
                                    <li><font color="red"><b>STPLS3D Challenge</b></font>: <a href="https://codalab.lisn.upsaclay.fr/competitions/4646">https://codalab.lisn.upsaclay.fr/competitions/4646</a>
                                    </li>
                                    <li>STPLS3D dataset: <a href="https://www.stpls3d.com">https://www.stpls3d.com</a>
                                    </li>
                                    <li>STPLS3D API: <a href="https://github.com/meidachen/STPLS3D">https://github.com/meidachen/STPLS3D</a>
                                    </li>
                                </ul>
                            </ul>
                            <!-- <p>
                                More information on the respective challenges can be found on their pages.
                            </p> -->
                            <br/>
                                <p>
                                    We are thankful to our sponsor for providing the following prizes. The prize award will be granted to the <b>Top 3</b> individuals and teams for <b>Each Challenge Track</b> on the leaderboard that provide a valid submission.
                                <table style="width: 100%;">
                                    <colgroup>
                                        <col span="1" style="width: 50%;"/>
                                        <col span="1" style="width: 35%;"/>
                                        <col span="1" style="width: 15%;"/>
                                    </colgroup>
                                    <tbody>
                                        <tr>
                                            
                                            <td><ul><ul><li><b>1st Place:</b></li></ul></ul></td>
                                            <td>$1,500 USD</td>
                                            <td><small>courtesy of </small><img width="50" src="2022/img/USC_ICT_Logo.png"/></td>

                                        </tr>
                                        <tr>
                                            <td><ul><ul><li><b>2nd Place:</b></li></ul></ul></td>
                                            <td>$1,000 USD</td>
                                            <td><small>courtesy of </small><img width="50" src="2022/img/USC_ICT_Logo.png"/></td>
                                        </tr>
                                        <tr>
                                            <td><ul><ul><li><b>3rd Place:</b></li></ul></ul></td>
                                            <td>$500 USD</td>
                                            <td><small>courtesy of </small><img width="50" src="2022/img/USC_ICT_Logo.png"/></td>
                                        </tr>
                                        <!-- <tr>
                                            <td><b>EVE Challenge Winner</b></td>
                                            <td>Tobii Eye Tracker 5</td>
                                            <td><small>courtesy of </small><img width="50" src="2021/img/tobii.jpg"/></td>
                                        </tr> -->
                                    </tbody>
                                </table>
                                </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <p><br/></p>

        <div class="row">
            <div class="col-xs-12"><a class="anchor" id="dates"></a>
                <h2>Important Dates</h2>
                <br/>
                <table class="table table-striped">
                    <tbody>
                    <tr>
                        <td>Workshop Proposal Accepted</td>
                        <td>April 12, 2022</td>
                    </tr>
                    <tr>
                        <td>Competition Starts</td>
                        <td>May 12, 2022</td>
                    </tr>
                    <tr>
                        <td>Competition Ends</td>
                        <td>September 23, 2022 (23:59 Pacific time)</td>
                    </tr>
                    <tr>
                        <td>Notification to Participants</td>
                        <td>September 27, 2022</td>
                    </tr>
                    <tr>
                        <td>Finalized Workshop Program (Half Day)</td>
                        <td>October 23, 2022 (8:30-12:00 EDT)</td>
                    </tr>
                    <tr id="schedule">
                        <td></td>
                        <td></td>
                    </tr>
                    </tbody>
                </table>
            </div>
        </div>
        <p><br/></p>

        <div class="row">
            <div class="col-xs-12"><a class="anchor" id="dates"></a>
                <h2>Preliminary Program Outline</h2>
                <br/>
                <table class="table table-striped">
                    <tbody>
                    <tr>
                        <td>08:30-08:35</td>
                        <td>Welcome Introduction</td>
                    </tr>
                    <tr>
                        <td>08:35-09:20</td>
                        <td>Invited Talk (Talk 1)</td>
                    </tr>
                    <tr>
                        <td>09:20-10:05</td>
                        <td>Invited Talk (Talk 2)</td>
                    </tr>
                    <tr>
                        <td>10:05-10:10</td>
                        <td>Coffee break</td>
                    </tr>
                    <tr>
                        <td>10:10-10:20</td>
                        <td>Awarding ceremony</td>
                    </tr>
                    <tr>
                        <td>10:20-10:40</td>
                        <td>Winner Talk (Track 1) + Q&A</td>
                    </tr>
                    <tr>
                        <td>10:40-11:00</td>
                        <td>Winner Talk (Track 2) + Q&A</td>
                    </tr>
                    <tr>
                        <td>11:00-11:20</td>
                        <td>Winner Talk (Track 3) + Q&A</td>
                    </tr>
                    <tr>
                        <td>11:20-11:55</td>
                        <td>Panel Discussion</td>
                    </tr>
                    <tr>
                        <td>11:55-12:00</td>
                        <td>Closing Remarks</td>
                    </tr>
                    <tr>
                        <td></td>
                        <td></td>
                    </tr>
                    </tbody>
                </table>
            </div>
        </div>
        <p><br/></p>


        <div class="row">
            <div class="col-xs-12"><a class="anchor" id="speakers"></a>
                <h2>Invited Keynote Speakers</h2>
                <br/>
                <div class="row speaker">
                    <div class="col-sm-3 speaker-pic">
                        <a href="https://3dom.fbk.eu/people/profile/remondino">
                            <img class="people-pic" src="./2022/img/people/fabio.jpeg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://3dom.fbk.eu/people/profile/remondino">Fabio Remondino
                            </a>
                            <h6>FBK Trento</h6>
                        </div>
                    </div>
                    <div class="col-sm-9">
                        <h3>3D point cloud classification with an eye on daily applications</h3><br/>
                        <!--<b>Abstract</b><p class="speaker-abstract"></p>-->
                        <div class="panel panel-default">
                            <div class="panel-heading" data-toggle="collapse" href="#jr-bio"
                                 style="cursor:pointer;text-align:center">
                                <b>Biography <span style="font-weight:normal">(click to expand/collapse)</span></b>
                            </div>
                            <div id="jr-bio" class="panel-collapse collapse in">
                                <div class="panel-body">
                                    <p class="speaker-bio">
                                        Fabio Remondino is the head of the <a href="https://3dom.fbk.eu/">3D Optical
                                        Metrology research unit</a> at FBK - Bruno Kessler Foundation, a public research
                                        center in Trento, Italy. He received a PhD in Photogrammetry from ETH Zurich in
                                        2006. His main research interests are in the field of reality-based 3D surveying
                                        and modeling, sensor and data fusion and 3D data classification. He is working
                                        in all automation aspects of the entire 3D reconstruction pipeline for
                                        applications in the industrial, environmental and heritage field. He is author
                                        of more than 200 articles in journals and conferences. He is involved in
                                        knowledge and technology transfer, organizing more than 30 conferences, 20
                                        summer schools and 5 tutorials. Fabio is currently serving as Vice-President of
                                        EuroSDR and he was President of ISPRS Technical Commission V and II (2012-2021)
                                        as well as vice-President of CIPA Heritage Documentation (2015 to 2019).
                                    </p>
                                </div>
                            </div>
                        </div>
                        <div class="panel-heading" data-toggle="collapse" href="#jr-bio"
                             style="cursor:pointer;text-align:center">

                        </div>
                    </div>
                </div>


                <div class="row speaker">
                    <div class="col-sm-3 speaker-pic">
                        <a href="https://loiclandrieu.com/">
                            <img class="people-pic" src="./2022/img/people/loic.jpeg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://loiclandrieu.com/">Loic Landrieu
                            </a>
                            <h6><a href="https://www.ign.fr/">IGN</a></h6>
                        </div>
                    </div>
                    <div class="col-sm-9">
                        <h3>Beyond Sliding Windows: Scaling Up 3D Deep Learning</h3><br/>
                        <!--<b>Abstract</b><p class="speaker-abstract"></p>-->
                        <div class="panel panel-default">
                            <div class="panel-heading" data-toggle="collapse" href="#jr-bio"
                                 style="cursor:pointer;text-align:center">
                                <b>Biography <span style="font-weight:normal">(click to expand/collapse)</span></b>
                            </div>
                            <div id="jr-bio" class="panel-collapse collapse in">
                                <div class="panel-body">
                                    <p class="speaker-bio">
                                        Loic Landrieu received his PhD from <a href="https://www.inria.fr/en">INRIA</a>
                                        and <a href="https://www.ecoledesponts.fr/en">ENPC</a>. He has since been a
                                        researcher at <a href="https://www.ign.fr/">IGN</a>, the French mapping agency,
                                        and focuses on developing new machine learning approaches for problems with
                                        spatial and temporal structures, such as the analysis of 3D point clouds or
                                        satellite time series. He is the main investigator of the ANR Ready3D on dynamic
                                        3D analysis for autonomous driving. Committed to open and reproducible research,
                                        he has participated in several open-source projects and released open-access
                                        large-scale benchmarks.

                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
		    
		    <div class="row">
                    <div class="col-xs-12"><a class="anchor" id="Invited Panel Speakers"></a>
                        <h2>Invited Panel Speakers</h2>
                    </div>
                </div>

                <div class="row">
                    <div class="col-xs-1"></div>
                    <div class="col-xs-2">
                        <a href="https://hszhao.github.io/">
                            <img class="people-pic" src="2022/img/people/hengshuangzhao.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://hszhao.github.io/">Hengshuang Zhao</a>
                            <h6>The University of Hong Kong (HKU)</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="http://tbirdal.me/">
                            <img class="people-pic" src="2022/img/people/Tolga.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="http://tbirdal.me/">Tolga Birdal</a>
                            <h6>Stanford University</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="https://people.csail.mit.edu/yuewang/">
                            <img class="people-pic" src="2022/img/people/Yue_wang.png"/>
                        </a>
                        <div class="people-name">
                            <a href="https://people.csail.mit.edu/yuewang/">Yue Wang</a>
                            <h6>Massachusetts Institute of Technology</h6>
                        </div>
                    </div>
			
		   <div class="col-xs-2">
                        <a href="https://pengsongyou.github.io/">
                            <img class="people-pic" src="2022/img/people/songyou.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://pengsongyou.github.io/">Songyou Peng</a>
                            <h6> ETH Zurich and Max Planck Institute</h6>
                        </div>
                    </div>
			
                    <div class="col-xs-2">
                        <a href="https://udayton.edu/directory/engineering/electrical_and_computer/singer-nina.php">
                            <img class="people-pic" src="2022/img/people/varney-nina.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://udayton.edu/directory/engineering/electrical_and_computer/singer-nina.php/">Nina Singer</a>
                            <h6>University of Dayton</h6>
                        </div>
                    </div>
		          <p><br/></p>
			
<!-- 		    <div class="col-xs-2">
                        <a href="https://yanx27.github.io/">
                            <img class="people-pic" src="2021/img/people/xu.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://yanx27.github.io/">Xu Yan</a>
                            <h6>The Chinese University of Hong Kong, Shenzhen</h6>
                        </div>
                    </div>
		
		    <div class="col-xs-2">
                        <a href="https://www.researchgate.net/profile/Zhuoxu-Huang">
                            <img class="people-pic" src="2021/img/people/zhuoxu.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://www.researchgate.net/profile/Zhuoxu-Huang">Zhuoxu Huang</a>
                            <h6>Wuhan University</h6>
                        </div>
                    </div> -->
			
			
                    
                </div>
                <p><br/></p>


<!--                 <div class="row">
                    <div class="col-xs-12"><a class="anchor" id="awards"></a>
                        <h2>Awards</h2>
                        <div class="award">
                            <h3> Winner Award
                                <span class="award-sponsor">sponsored by <a href="https://www.sensat.co/"
                                                                            target="_blank"><img
                                        src="./2021/img/sensat.png"/></a>
	    </span></h3>
                            <p><br/>
                                Team <b>BUPT.BIGO.GAGO.WHU</b><br/>
				<b>IDS-Net: Improved Down-sampling Method for Semantic Segmentation of Class-imbalanced Large-Scale Point Clouds</b><br />
                                <i>Zeqiang Wei, Kai Jin, Kuan Song, Tianyu Xiu, Xiuzhuang Zhou, and Guodong Guo</i>
                            </p>
                        </div>

                        <div class="award">
                            <h3> 2nd Place Award
                                <span class="award-sponsor">	    </span></h3>
                            <p><br/>
                                Team <b>Deep Bit Lab</b><br/>
				<b>City-scale point cloud semantic segmentation via coarse-to-fine small object refinement</b><br />
                                <i>Xu Yan, Zhen Li, Chaoda Zheng, Haiming Zhang, Jiantao Gao, Wending Zhou, Yinghong
                                    Liao, Zhihao Yuan, Sheng Wang, Shuguang Cui</i>
                            </p>
                        </div>

                         <div class="award">
                            <h3> 3rd Place Award
                                <span class="award-sponsor">	    </span></h3>
                            <p><br/>
                                Team <b>what‘s up?</b><br/>
				<b>Boosting Semantic Segmentation in Urban-Scale Point Clouds via Transformers</b><br />
                                <i>Zhuoxu Huang, Zhiyou Zhao, Banghuai Li, Huabin Huang, Ye Yuan</i>
                            </p>
                        </div>



                            </p>
                        </div>
                    </div>
                </div>
                <p><br/></p> -->


                <div class="row">
                    <div class="col-xs-12"><a class="anchor" id="organizers"></a>
                        <h2>Organizers</h2>
                    </div>
                </div>

                <div class="row">
                    <div class="col-xs-1"></div>
                    <div class="col-xs-2">
                        <a href="https://qingyonghu.github.io/">
                            <img class="people-pic" src="2022/img/people/qingyong.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://qingyonghu.github.io/">Qingyong Hu</a>
                            <h6>University of Oxford</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="https://scholar.google.com/citations?user=ii7ZwfQAAAAJ">
                            <img class="people-pic" src="2022/img/people/Meida.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://www.linkedin.com/in/meida-chen-938a265b/">Meida Chen</a>
                            <h6>University of Southern California - Institute for Creative Technologies</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="https://www.cs.ox.ac.uk/people/ta-ying.cheng/">
                            <img class="people-pic" src="2022/img/people/Ta-Ying.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://www.cs.ox.ac.uk/people/ta-ying.cheng/">Ta-Ying Cheng</a>
                            <h6>University of Oxford</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="https://uk.linkedin.com/in/fakharkhalid">
                            <img class="people-pic" src="2022/img/people/Khalid_7.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://uk.linkedin.com/in/fakharkhalid">Sheikh Khalid</a>
                            <h6>Sensat LTD.</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="https://yang7879.github.io/">
                            <img class="people-pic" src="2022/img/people/BoYang.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://yang7879.github.io/">Bo Yang</a>
                            <h6>The Hong Kong Polytechnic University</h6>
                        </div>
                    </div>
                    <div class="col-xs-1"></div>
                </div>
                <p><br/></p>
                <div class="row">
                    <div class="col-xs-1"></div>
                    <div class="col-xs-2">
                        <a href="http://www.ronnieclark.co.uk/">
                            <img class="people-pic" src="2022/img/people/Ronnie.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="http://www.ronnieclark.co.uk/">Ronarld Clark</a>
                            <h6>Imperial College London</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="http://yulanguo.me/">
                            <img class="people-pic" src="2022/img/people/yulan.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="http://yulanguo.me/">Yulan Guo</a>
                            <h6>National University of Defense Technology</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="https://www.cs.bham.ac.uk/~leonarda/">
                            <img class="people-pic" src="2022/img/people/al.jpg"/>
                        </a>
                        <div class="people-name">
                            <a href="https://www.cs.bham.ac.uk/~leonarda/">Aleš Leonardis</a>
                            <h6>University of Birmingham</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="https://www.cs.ox.ac.uk/people/niki.trigoni/">
                            <img class="people-pic" src="2022/img/people/Niki.png"/>
                        </a>
                        <div class="people-name">
                            <a href="https://www.cs.ox.ac.uk/people/niki.trigoni/">Niki Trigoni</a>
                            <h6>University of Oxford</h6>
                        </div>
                    </div>
                    <div class="col-xs-2">
                        <a href="https://www.cs.ox.ac.uk/people/andrew.markham/">
                            <img class="people-pic" src="2022/img/people/Andrew_markham.png"/>
                        </a>
                        <div class="people-name">
                            <a href="https://www.cs.ox.ac.uk/people/andrew.markham/">Andrew Markham</a>
                            <h6>University of Oxford</h6>
                        </div>
                    </div>
                </div>
                <p><br/></p>

                <div class="row">
                    <div class="col-xs-12"><a class="anchor" id="sponsors"></a>
                        <h2>Workshop sponsored by:</h2>
                    </div>
                </div>

                <div class="row">
                    <div class="col-xs-4 sponsor">
                        <a href="https://ict.usc.edu/"><img src="2022/img/USC_ICT_Logo.png"/></a>
                    </div>
                    <div class="col-xs-4 sponsor">
                        <a href="https://www.sensat.co.uk/"><img src="2022/img/sensat.png"/></a>
                    </div>
                    <!--                    <div class="col-xs-4 sponsor">-->
                    <!--                        <a href="https://www.tobii.com/"><img src="2021/img/tobii.jpg"/></a>-->
                    <!--                    </div>-->
                    <!--                    <div class="col-xs-4 sponsor">-->
                    <!--                        <a href="https://www.google.com/"><img src="2021/img/google.png"/></a>-->
                    <!--                    </div>-->
                </div>
                <p><br/></p>

                <div class="row">
                    <div class="col-xs-12"><a class="anchor" id="previous"></a>
                        <h2>Previous years' workshops:</h2>
                    </div>
                </div>

                <div class="row">
                    <div class="col-xs-12"><a class="anchor" id="previous"></a>
                        <ul><li>
                        <b>Urban3D@ICCV2021: </b> <font color="blue"><a href="https://urban3dchallenge.github.io/2021" target="_blank">https://urban3dchallenge.github.io/2021</a></font>
                        </li></ul>
                    </div>
                </div>


            </div>
        </div>

        <hr>
        <div class="section text-gray" id="footer">
            <div class="container">
                <div class="row">
                    <div class="col-sm-14" style="text-align:right;">
                        <small>This work is sponsored by the U.S. Army Research Laboratory (ARL) under contract number W911NF-14-D-0005. Statements, expressed opinions, and content included do not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred.</small>
                    </div>
                    <br><br>
                </div>
            </div>
        </div>


        <script type="text/javascript" src="/static/js/jquery.min.js"></script>
        <script type="text/javascript" src="/static/js/bootstrap.min.js"></script>
</body>
</html>
